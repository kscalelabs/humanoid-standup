
# Currently tests:
- Hidden layer size of 256 shows progress (loss is based on state.q[2])

- setting std to zero makes rewards nans why. I wonder if there NEEDS to be randomization in the enviornment

- ctrl cost is whats giving nans? interesting?
- it is unrelated to randomization of enviornmnet. i think gradient related

- first thing to become nans seems to be actor loss and scores. after that, everything becomes nans

- fixed entropy epsilon. hope this works now.


- training clipped mus right now

- `equinox.internal.debug_backward_nan`
- JAX_DEBUG_NANS=1

- lr = 0 still nan in minimum example
- problem maybe in gradient clipping? as per https://github.com/google/jax/discussions/6440
- ^nope

- i think its a problem with the clipping